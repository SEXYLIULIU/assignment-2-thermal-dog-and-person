{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SEXYLIULIU/assignment-2-thermal-dog-and-person/blob/main/Assignment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khklHXj-K4-R",
        "outputId": "a9211a15-cdee-4d90-b0e7-d5560d84455e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files in /content:\n",
            "['.config', 'thermal_data', 'sample_data']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# List all files in /content to confirm the file name and location\n",
        "print(\"Files in /content:\")\n",
        "print(os.listdir('/content'))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7U_c03KfPJwR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Organize extracted file with ideal structure**"
      ],
      "metadata": {
        "id": "l5kq3ub26JOW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nM7KUf1mLKJw",
        "outputId": "37d9d92f-6f6a-49d0-c624-5bda07104370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted successfully.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Define the path to the uploaded zip files\n",
        "dog_zip_path = '/content/Thermal Dogs and People.v5-raw-images_dogclassonly.yolov11.zip'\n",
        "person_zip_path = '/content/Thermal Dogs and People.v4-raw-images_personclassonly.yolov11.zip'\n",
        "\n",
        "# Define the extraction directories\n",
        "dog_extract_dir = '/content/thermal_data/dog'\n",
        "person_extract_dir = '/content/thermal_data/person'\n",
        "\n",
        "# Ensure extraction directories exist\n",
        "os.makedirs(dog_extract_dir, exist_ok=True)\n",
        "os.makedirs(person_extract_dir, exist_ok=True)\n",
        "\n",
        "# Unzip the files\n",
        "with zipfile.ZipFile(dog_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(dog_extract_dir)\n",
        "\n",
        "with zipfile.ZipFile(person_zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(person_extract_dir)\n",
        "\n",
        "print(\"Files extracted successfully.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2.Data Preparation and Preprocessing**"
      ],
      "metadata": {
        "id": "Ow8Bj_3-6hD2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tosq53-mLhNo",
        "outputId": "b6a5a88d-a2c1-40ee-ec3c-0fe04618391e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files organized into classification structure.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "from sklearn.model_selection import train_test_split\n",
        "import glob\n",
        "\n",
        "# Base directory for the classification dataset\n",
        "base_dir = '/content/thermal_classification'\n",
        "os.makedirs(base_dir, exist_ok=True)\n",
        "\n",
        "# Create train, valid, and test directories for each class\n",
        "for split in ['train', 'valid', 'test']:\n",
        "    for class_name in ['dog', 'person']:\n",
        "        os.makedirs(os.path.join(base_dir, split, class_name), exist_ok=True)\n",
        "\n",
        "# Gather all images from the extracted directories\n",
        "dog_images = glob.glob(f\"{dog_extract_dir}/**/*.jpg\", recursive=True)\n",
        "person_images = glob.glob(f\"{person_extract_dir}/**/*.jpg\", recursive=True)\n",
        "\n",
        "# Split data into train (70%), valid (15%), and test (15%)\n",
        "dog_train, dog_temp = train_test_split(dog_images, test_size=0.3, random_state=42)\n",
        "dog_valid, dog_test = train_test_split(dog_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "person_train, person_temp = train_test_split(person_images, test_size=0.3, random_state=42)\n",
        "person_valid, person_test = train_test_split(person_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Function to move files to the classification folders\n",
        "def move_files(file_list, target_dir):\n",
        "    for file_path in file_list:\n",
        "        shutil.move(file_path, target_dir)\n",
        "\n",
        "# Move images to respective directories\n",
        "move_files(dog_train, os.path.join(base_dir, 'train', 'dog'))\n",
        "move_files(dog_valid, os.path.join(base_dir, 'valid', 'dog'))\n",
        "move_files(dog_test, os.path.join(base_dir, 'test', 'dog'))\n",
        "\n",
        "move_files(person_train, os.path.join(base_dir, 'train', 'person'))\n",
        "move_files(person_valid, os.path.join(base_dir, 'valid', 'person'))\n",
        "move_files(person_test, os.path.join(base_dir, 'test', 'person'))\n",
        "\n",
        "print(\"Files organized into classification structure.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6E0ER86LjZ6",
        "outputId": "aa3bc49c-9c94-4ed8-fe9e-23b196d1c23e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data loaders created for train, validation, and test sets.\n"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define transformations including resizing, normalization, and augmentation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Load datasets\n",
        "train_dataset = ImageFolder(root=os.path.join(base_dir, 'train'), transform=transform)\n",
        "valid_dataset = ImageFolder(root=os.path.join(base_dir, 'valid'), transform=transform)\n",
        "test_dataset = ImageFolder(root=os.path.join(base_dir, 'test'), transform=transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=32, shuffle=False)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "print(\"Data loaders created for train, validation, and test sets.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shrJUn58LoMD",
        "outputId": "62d0e4a4-a152-46d0-8d1e-ac574b06711e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n",
            "100%|██████████| 233M/233M [00:03<00:00, 65.5MB/s]\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# AlexNet\n",
        "alexnet = models.alexnet(pretrained=True)\n",
        "alexnet.classifier[6] = torch.nn.Linear(alexnet.classifier[6].in_features, 2)  # 2 classes: dog and person\n",
        "alexnet = alexnet.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQyB-bvJLq26",
        "outputId": "c75840cb-b07c-4059-a984-fbccb297275e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
            "100%|██████████| 44.7M/44.7M [00:00<00:00, 149MB/s]\n"
          ]
        }
      ],
      "source": [
        "# ResNet-18\n",
        "resnet = models.resnet18(pretrained=True)\n",
        "resnet.fc = torch.nn.Linear(resnet.fc.in_features, 2)\n",
        "resnet = resnet.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KTM7x6aaLtNl",
        "outputId": "4b5e7c8a-fd75-4230-92a5-463cb7c173b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
            "100%|██████████| 13.6M/13.6M [00:00<00:00, 129MB/s]\n"
          ]
        }
      ],
      "source": [
        "# MobileNet\n",
        "mobilenet = models.mobilenet_v2(pretrained=True)\n",
        "mobilenet.classifier[1] = torch.nn.Linear(mobilenet.classifier[1].in_features, 2)\n",
        "mobilenet = mobilenet.to(device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4.Training and Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "rxfy7We467aZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpHAPFO_LvuB",
        "outputId": "22c8fe55-5239-4d60-ea9a-fb201d341e24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AlexNet...\n",
            "Epoch 1/5, Loss: 0.7448, Val Acc: 0.4833\n",
            "Epoch 2/5, Loss: 0.8028, Val Acc: 0.4667\n",
            "Epoch 3/5, Loss: 0.7420, Val Acc: 0.4667\n",
            "Epoch 4/5, Loss: 0.7559, Val Acc: 0.5000\n",
            "Epoch 5/5, Loss: 0.7842, Val Acc: 0.5000\n",
            "Training ResNet-18...\n",
            "Epoch 1/5, Loss: 0.8485, Val Acc: 0.5833\n",
            "Epoch 2/5, Loss: 0.7022, Val Acc: 0.4333\n",
            "Epoch 3/5, Loss: 0.7255, Val Acc: 0.3667\n",
            "Epoch 4/5, Loss: 0.7009, Val Acc: 0.4833\n",
            "Epoch 5/5, Loss: 0.6894, Val Acc: 0.4333\n",
            "Training MobileNet...\n",
            "Epoch 1/5, Loss: 0.7167, Val Acc: 0.5833\n",
            "Epoch 2/5, Loss: 0.7226, Val Acc: 0.4833\n",
            "Epoch 3/5, Loss: 0.7019, Val Acc: 0.4667\n",
            "Epoch 4/5, Loss: 0.7138, Val Acc: 0.4667\n",
            "Epoch 5/5, Loss: 0.7104, Val Acc: 0.4167\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Optimizers for each model\n",
        "alexnet_optimizer = optim.SGD(alexnet.parameters(), lr=0.001, momentum=0.9)\n",
        "resnet_optimizer = optim.Adam(resnet.parameters(), lr=0.0001)\n",
        "mobilenet_optimizer = optim.SGD(mobilenet.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Training function\n",
        "def train_model(model, optimizer, train_loader, val_loader, num_epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss, correct = 0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).type(torch.float).sum().item()\n",
        "\n",
        "        # Validation accuracy\n",
        "        val_correct = sum((model(images.to(device)).argmax(1) == labels.to(device)).type(torch.float).sum().item() for images, labels in val_loader)\n",
        "        val_accuracy = val_correct / len(val_loader.dataset)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "# Train each model\n",
        "print(\"Training AlexNet...\")\n",
        "train_model(alexnet, alexnet_optimizer, train_loader, valid_loader)\n",
        "\n",
        "print(\"Training ResNet-18...\")\n",
        "train_model(resnet, resnet_optimizer, train_loader, valid_loader)\n",
        "\n",
        "print(\"Training MobileNet...\")\n",
        "train_model(mobilenet, mobilenet_optimizer, train_loader, valid_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5.Evaluate Models on the Test Set**"
      ],
      "metadata": {
        "id": "7ijRPa0X7Dan"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHIqCkVrPOPs",
        "outputId": "e79e9273-3e99-4b1e-affc-fa0b826abe9d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating AlexNet on test set:\n",
            "Test Accuracy: 0.5000, F1 Score: 0.3333\n",
            "\n",
            "Evaluating ResNet-18 on test set:\n",
            "Test Accuracy: 0.2903, F1 Score: 0.2896\n",
            "\n",
            "Evaluating MobileNet on test set:\n",
            "Test Accuracy: 0.3387, F1 Score: 0.3245\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "def evaluate_model(model, test_loader):\n",
        "    model.eval()\n",
        "    all_preds, all_labels = [], []\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            all_preds.extend(outputs.argmax(1).cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = accuracy_score(all_labels, all_preds)\n",
        "    f1 = f1_score(all_labels, all_preds, average='weighted')\n",
        "    print(f\"Test Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}\")\n",
        "\n",
        "# Evaluate each model\n",
        "print(\"\\nEvaluating AlexNet on test set:\")\n",
        "evaluate_model(alexnet, test_loader)\n",
        "\n",
        "print(\"\\nEvaluating ResNet-18 on test set:\")\n",
        "evaluate_model(resnet, test_loader)\n",
        "\n",
        "print(\"\\nEvaluating MobileNet on test set:\")\n",
        "evaluate_model(mobilenet, test_loader)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results show low test accuracy and F1 scores for each model, which might indicate issues in model performance due to factors such as:\n",
        "\n",
        "Dataset Size: Limited training data can make it hard for deep models to generalize well, leading to overfitting or underfitting.\n",
        "\n",
        "Class Imbalance: If there’s an imbalance between the number of \"dog\" and \"person\" images, models may struggle to learn equally for both classes.\n",
        "\n",
        "Insufficient Training Epochs: Five epochs may not be enough for the models to reach optimal performance.\n",
        "\n",
        "Hyperparameter Settings: The learning rates, batch size, or other settings might need tuning.\n",
        "\n",
        "Complexity of the Task: Thermal images might be harder to classify directly without specific adjustments, like customized preprocessing or augmentation."
      ],
      "metadata": {
        "id": "23mR6l5r7VGL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1.Data Augmentation and Preprocessing Enhancements**"
      ],
      "metadata": {
        "id": "Ema1mj6R7eyp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "hKBC6jMbPbu2"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2),  # New augmentation\n",
        "    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),   # Random crop for more variability\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Increase Training Epochs**"
      ],
      "metadata": {
        "id": "gpxjyAuS7lUA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Rl9QaPcPsr6",
        "outputId": "607c5539-b0f0-48c1-fad2-eb3165f19b3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Loss: 0.7008, Val Acc: 0.4500\n",
            "Epoch 2/15, Loss: 0.6958, Val Acc: 0.4667\n",
            "Epoch 3/15, Loss: 0.6896, Val Acc: 0.4500\n",
            "Epoch 4/15, Loss: 0.6974, Val Acc: 0.3167\n",
            "Epoch 5/15, Loss: 0.6907, Val Acc: 0.4167\n",
            "Epoch 6/15, Loss: 0.6911, Val Acc: 0.4000\n",
            "Epoch 7/15, Loss: 0.6928, Val Acc: 0.3833\n",
            "Epoch 8/15, Loss: 0.6893, Val Acc: 0.3667\n",
            "Epoch 9/15, Loss: 0.6776, Val Acc: 0.4333\n",
            "Epoch 10/15, Loss: 0.6864, Val Acc: 0.3833\n",
            "Epoch 11/15, Loss: 0.6770, Val Acc: 0.4167\n",
            "Epoch 12/15, Loss: 0.6865, Val Acc: 0.3500\n",
            "Epoch 13/15, Loss: 0.6890, Val Acc: 0.2667\n",
            "Epoch 14/15, Loss: 0.6865, Val Acc: 0.4500\n",
            "Epoch 15/15, Loss: 0.6852, Val Acc: 0.4333\n",
            "Epoch 1/15, Loss: 0.6687, Val Acc: 0.4333\n",
            "Epoch 2/15, Loss: 0.6401, Val Acc: 0.4167\n",
            "Epoch 3/15, Loss: 0.6935, Val Acc: 0.4833\n",
            "Epoch 4/15, Loss: 0.6485, Val Acc: 0.4667\n",
            "Epoch 5/15, Loss: 0.6602, Val Acc: 0.4167\n"
          ]
        }
      ],
      "source": [
        "# Increase epochs in the training loop\n",
        "train_model(alexnet, alexnet_optimizer, train_loader, valid_loader, num_epochs=15)\n",
        "train_model(resnet, resnet_optimizer, train_loader, valid_loader, num_epochs=15)\n",
        "train_model(mobilenet, mobilenet_optimizer, train_loader, valid_loader, num_epochs=15)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. Adjust Learning Rates and Optimizers**"
      ],
      "metadata": {
        "id": "mvgyN-ZJ76Ah"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tldCAy71dLBt"
      },
      "outputs": [],
      "source": [
        "# Adjusted learning rates\n",
        "alexnet_optimizer = optim.SGD(alexnet.parameters(), lr=0.0005, momentum=0.9)\n",
        "resnet_optimizer = optim.Adam(resnet.parameters(), lr=0.00005)\n",
        "mobilenet_optimizer = optim.SGD(mobilenet.parameters(), lr=0.0005, momentum=0.9)\n",
        "\n",
        "# Add a scheduler to reduce the learning rate during training if validation accuracy plateaus\n",
        "alexnet_scheduler = optim.lr_scheduler.StepLR(alexnet_optimizer, step_size=5, gamma=0.1)\n",
        "resnet_scheduler = optim.lr_scheduler.StepLR(resnet_optimizer, step_size=5, gamma=0.1)\n",
        "mobilenet_scheduler = optim.lr_scheduler.StepLR(mobilenet_optimizer, step_size=5, gamma=0.1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Re-run Training with Modified Settings**"
      ],
      "metadata": {
        "id": "gPU1mvk27-7k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "n8iCwkRQdDq4",
        "outputId": "a9235ba6-e0f2-4433-bed5-ac6d0847510b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training AlexNet with scheduler...\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'alexnet' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-2bf0e2a693f2>\u001b[0m in \u001b[0;36m<cell line: 28>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Re-train each model with scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training AlexNet with scheduler...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mtrain_model_with_scheduler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malexnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malexnet_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malexnet_scheduler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training ResNet-18 with scheduler...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'alexnet' is not defined"
          ]
        }
      ],
      "source": [
        "def train_model_with_scheduler(model, optimizer, scheduler, train_loader, val_loader, num_epochs=15):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        total_loss, correct = 0, 0\n",
        "        for images, labels in train_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = torch.nn.CrossEntropyLoss()(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            correct += (outputs.argmax(1) == labels).type(torch.float).sum().item()\n",
        "\n",
        "        # Scheduler step\n",
        "        scheduler.step()\n",
        "\n",
        "        # Validation accuracy\n",
        "        val_correct = sum((model(images.to(device)).argmax(1) == labels.to(device)).type(torch.float).sum().item() for images, labels in val_loader)\n",
        "        val_accuracy = val_correct / len(val_loader.dataset)\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss / len(train_loader):.4f}, Val Acc: {val_accuracy:.4f}\")\n",
        "\n",
        "# Re-train each model with scheduler\n",
        "print(\"Training AlexNet with scheduler...\")\n",
        "train_model_with_scheduler(alexnet, alexnet_optimizer, alexnet_scheduler, train_loader, valid_loader)\n",
        "\n",
        "print(\"Training ResNet-18 with scheduler...\")\n",
        "train_model_with_scheduler(resnet, resnet_optimizer, resnet_scheduler, train_loader, valid_loader)\n",
        "\n",
        "print(\"Training MobileNet with scheduler...\")\n",
        "train_model_with_scheduler(mobilenet, mobilenet_optimizer, mobilenet_scheduler, train_loader, valid_loader)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0tsPxg/XW9UJgEJM7smiO",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}